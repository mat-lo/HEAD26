<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Camera Feed with OpenAI Analysis</title>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        background: #000000;
        min-height: 100vh;
        display: flex;
        justify-content: center;
        align-items: center;
        padding: 20px;
      }

      .container {
        background: white;
        border-radius: 15px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        max-width: 900px;
        width: 100%;
        overflow: hidden;
      }

      .header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 30px;
        text-align: center;
      }

      .header h1 {
        font-size: 28px;
        margin-bottom: 8px;
      }

      .header p {
        font-size: 14px;
        opacity: 0.9;
      }

      .content {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 20px;
        padding: 30px;
      }

      @media (max-width: 768px) {
        .content {
          grid-template-columns: 1fr;
        }
      }

      .camera-section,
      .analysis-section {
        display: flex;
        flex-direction: column;
        gap: 15px;
      }

      h2 {
        font-size: 18px;
        color: #333;
        border-bottom: 3px solid #667eea;
        padding-bottom: 10px;
      }

      video {
        width: 100%;
        height: auto;
        background: #000;
        border-radius: 10px;
        border: 2px solid #667eea;
      }

      canvas {
        display: none;
      }

      .controls {
        display: flex;
        gap: 10px;
        flex-wrap: wrap;
      }

      button {
        flex: 1;
        padding: 12px 20px;
        border: none;
        border-radius: 8px;
        font-size: 14px;
        font-weight: 600;
        cursor: pointer;
        transition: all 0.3s ease;
        min-width: 120px;
      }

      .btn-primary {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
      }

      .btn-primary:hover:not(:disabled) {
        transform: translateY(-2px);
        box-shadow: 0 10px 25px rgba(102, 126, 234, 0.4);
      }

      .btn-primary:disabled {
        opacity: 0.6;
        cursor: not-allowed;
      }

      .btn-secondary {
        background: #f0f0f0;
        color: #333;
        border: 2px solid #ddd;
      }

      .btn-secondary:hover:not(:disabled) {
        background: #e0e0e0;
        border-color: #667eea;
      }

      .btn-secondary:disabled {
        opacity: 0.5;
        cursor: not-allowed;
      }

      .status {
        background: #f5f5f5;
        padding: 12px;
        border-radius: 8px;
        font-size: 13px;
        color: #666;
        border-left: 4px solid #667eea;
      }

      .status.success {
        border-left-color: #10b981;
        background: #ecfdf5;
        color: #047857;
      }

      .status.error {
        border-left-color: #ef4444;
        background: #fef2f2;
        color: #dc2626;
      }

      .status.loading {
        border-left-color: #f59e0b;
        background: #fffbeb;
        color: #d97706;
        display: flex;
        align-items: center;
        gap: 8px;
      }

      .spinner {
        display: inline-block;
        width: 12px;
        height: 12px;
        border: 2px solid #f59e0b;
        border-top: 2px solid transparent;
        border-radius: 50%;
        animation: spin 0.8s linear infinite;
      }

      @keyframes spin {
        to {
          transform: rotate(360deg);
        }
      }

      .analysis-output {
        background: #f9fafb;
        padding: 15px;
        border-radius: 8px;
        border: 1px solid #e5e7eb;
        min-height: 150px;
        max-height: 300px;
        overflow-y: auto;
        font-size: 14px;
        line-height: 1.6;
        color: #374151;
      }

      .analysis-output:empty::before {
        content: "Analysis results will appear here...";
        color: #999;
        font-style: italic;
      }

      .analysis-output pre {
        background: #1f2937;
        color: #10b981;
        padding: 12px;
        border-radius: 6px;
        font-family: "Monaco", "Menlo", "Ubuntu Mono", monospace;
        font-size: 13px;
        overflow-x: auto;
        margin: 0;
      }

      .timestamp {
        font-size: 12px;
        color: #999;
        margin-top: 8px;
      }

      .error-message {
        color: #dc2626;
        font-size: 13px;
        margin-top: 5px;
      }

      input[type="password"] {
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 6px;
        font-size: 14px;
        width: 100%;
        margin-bottom: 10px;
      }

      .api-key-section {
        background: #fef3c7;
        padding: 15px;
        border-radius: 8px;
        border-left: 4px solid #f59e0b;
        margin-bottom: 15px;
      }

      .api-key-section p {
        font-size: 13px;
        color: #92400e;
        margin-bottom: 10px;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="header">
        <h1>üì∑ Camera Feed Analyzer</h1>
        <p>Captures images every 10 seconds and analyzes them with OpenAI</p>
      </div>

      <div class="content">
        <div class="camera-section">
          <h2>Camera Feed</h2>
          <div class="api-key-section">
            <p>‚ö†Ô∏è Enter your OpenAI API Key to enable analysis:</p>
            <input type="password" id="apiKey" placeholder="sk-..." />
          </div>
          <video id="video" autoplay playsinline></video>
          <canvas id="canvas"></canvas>
          <div class="controls">
            <button class="btn-primary" id="startBtn">Start Camera</button>
            <button class="btn-secondary" id="stopBtn" disabled>
              Stop Camera
            </button>
          </div>
          <div class="status" id="cameraStatus">Ready to start</div>
        </div>

        <div class="analysis-section">
          <h2>Analysis Results</h2>
          <div class="status" id="analysisStatus">Waiting for camera...</div>
          <div class="analysis-output" id="analysisOutput"></div>
          <div class="timestamp" id="timestamp"></div>
        </div>
      </div>
    </div>

    <script>
      // Elements
      const video = document.getElementById("video");
      const canvas = document.getElementById("canvas");
      const startBtn = document.getElementById("startBtn");
      const stopBtn = document.getElementById("stopBtn");
      const cameraStatus = document.getElementById("cameraStatus");
      const analysisStatus = document.getElementById("analysisStatus");
      const analysisOutput = document.getElementById("analysisOutput");
      const timestamp = document.getElementById("timestamp");
      const apiKeyInput = document.getElementById("apiKey");

      // State
      let stream = null;
      let analyzeInterval = null;
      let isAnalyzing = false;

      // Start camera
      async function startCamera() {
        try {
          stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: "user" },
            audio: false,
          });
          video.srcObject = stream;
          startBtn.disabled = true;
          stopBtn.disabled = false;
          cameraStatus.textContent =
            "‚úì Camera active - will analyze every 10 seconds";
          cameraStatus.classList.add("success");
          analysisOutput.innerHTML = "";

          // Start capturing every 10 seconds
          analyzeInterval = setInterval(captureAndAnalyze, 10000);
          // Also capture immediately
          captureAndAnalyze();
        } catch (error) {
          cameraStatus.textContent = `‚úó Error: ${error.message}`;
          cameraStatus.classList.add("error");
          console.error("Camera error:", error);
        }
      }

      // Stop camera
      function stopCamera() {
        if (stream) {
          stream.getTracks().forEach((track) => track.stop());
        }
        if (analyzeInterval) {
          clearInterval(analyzeInterval);
        }
        startBtn.disabled = false;
        stopBtn.disabled = true;
        cameraStatus.textContent = "Camera stopped";
        cameraStatus.classList.remove("success");
        analysisStatus.textContent = "Camera stopped";
        analysisStatus.classList.remove("loading");
      }

      // Capture frame and send to OpenAI
      async function captureAndAnalyze() {
        if (!video.videoWidth || !video.videoHeight) return;

        // Check if API key is set
        const apiKey = apiKeyInput.value.trim();
        if (!apiKey) {
          analysisStatus.textContent = "‚ö†Ô∏è Please enter your OpenAI API key";
          analysisStatus.classList.remove("loading", "success", "error");
          return;
        }

        try {
          // Set canvas size and draw current video frame
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          const ctx = canvas.getContext("2d");
          ctx.drawImage(video, 0, 0);

          // Convert to base64
          const imageBase64 = canvas.toDataURL("image/jpeg").split(",")[1];

          // Update status
          analysisStatus.innerHTML =
            '<span class="spinner"></span> Analyzing image...';
          analysisStatus.classList.add("loading");
          analysisStatus.classList.remove("success", "error");

          // Send to OpenAI
          const response = await fetch(
            "https://api.openai.com/v1/chat/completions",
            {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
                Authorization: `Bearer ${apiKey}`,
              },
              body: JSON.stringify({
                model: "gpt-4o-2024-08-06",
                messages: [
                  {
                    role: "user",
                    content: [
                      {
                        type: "text",
                        text: "Analyze this image and respond with a JSON object containing: { isHat: boolean }. Determine if there is a hat visible in the image.",
                      },
                      {
                        type: "image_url",
                        image_url: {
                          url: `data:image/jpeg;base64,${imageBase64}`,
                        },
                      },
                    ],
                  },
                ],
                max_completion_tokens: 100,
                response_format: { type: "json_object" },
              }),
            },
          );

          if (!response.ok) {
            const errorData = await response.json();
            throw new Error(
              errorData.error?.message || `API error: ${response.status}`,
            );
          }

          const data = await response.json();
          console.log("Full response from OpenAI:", data);
          const rawContent = data.choices[0].message.content;
          console.log("Raw content:", rawContent);

          // Parse JSON response
          let parsedResponse;
          try {
            parsedResponse = JSON.parse(rawContent);
          } catch (e) {
            console.error("Failed to parse JSON response:", e);
            parsedResponse = { isHat: null, error: "Failed to parse response" };
          }

          if (!rawContent) {
            console.warn(
              "Empty response from API. Finish reason:",
              data.choices[0].finish_reason,
            );
          }

          // Update output with formatted JSON
          analysisOutput.innerHTML = `<pre>${JSON.stringify(parsedResponse, null, 2)}</pre>`;
          timestamp.textContent = `Last analyzed: ${new Date().toLocaleTimeString()}`;
          analysisStatus.innerHTML = "‚úì Analysis complete";
          analysisStatus.classList.remove("loading", "error");
          analysisStatus.classList.add("success");
        } catch (error) {
          analysisStatus.innerHTML = `‚úó ${error.message}`;
          analysisStatus.classList.remove("loading", "success");
          analysisStatus.classList.add("error");
          console.error("Analysis error:", error);
        }
      }

      // Event listeners
      startBtn.addEventListener("click", startCamera);
      stopBtn.addEventListener("click", stopCamera);

      // Initialize status
      cameraStatus.textContent = "Ready to start";
    </script>
  </body>
</html>
